"""
ACE Type Definitions and Schemas

Defines the data structures for Agentic Context Engineering (ACE):
- PlaybookEntry: Individual insights/strategies in the playbook
- PlaybookState: Complete playbook with metadata
- ReflectionInsight: Insights generated by reflector
- PlaybookDelta: Changes to apply to playbook
"""

from typing import Literal, Optional, List, Dict, Any
from datetime import datetime
from pydantic import BaseModel, Field
from typing_extensions import TypedDict


# ============================================================================
# Playbook Entries
# ============================================================================

class PlaybookEntry(BaseModel):
    """
    Individual entry in the evolving playbook.

    Represents a learned strategy, pattern, or pitfall discovered through
    agent execution and reflection.

    Attributes:
        id: Unique identifier for this entry
        content: The insight/strategy text
        category: Whether this is helpful or harmful
        helpful_count: Number of times this led to success
        harmful_count: Number of times this led to failure
        confidence_score: Confidence in this insight (0-1)
        created_at: When this entry was first added
        last_updated: When this entry was last modified
        source_executions: Execution IDs that contributed to this insight
        tags: Categorization tags for filtering
        metadata: Additional context
    """
    id: str = Field(..., description="Unique identifier (UUID)")
    content: str = Field(..., min_length=10, description="The insight/strategy text")
    category: Literal["helpful", "harmful", "neutral"] = Field(
        ..., description="Impact category"
    )
    helpful_count: int = Field(default=0, ge=0, description="Success count")
    harmful_count: int = Field(default=0, ge=0, description="Failure count")
    confidence_score: float = Field(
        default=0.5, ge=0.0, le=1.0, description="Confidence (0-1)"
    )
    created_at: datetime = Field(default_factory=datetime.now)
    last_updated: datetime = Field(default_factory=datetime.now)
    source_executions: List[str] = Field(
        default_factory=list, description="Execution IDs contributing to this"
    )
    tags: List[str] = Field(default_factory=list, description="Categorization tags")
    metadata: Dict[str, Any] = Field(default_factory=dict, description="Extra context")

    def update_success(self):
        """Record a successful application of this insight."""
        self.helpful_count += 1
        self.last_updated = datetime.now()
        self._recalculate_confidence()

    def update_failure(self):
        """Record a failed application of this insight."""
        self.harmful_count += 1
        self.last_updated = datetime.now()
        self._recalculate_confidence()

    def _recalculate_confidence(self):
        """Update confidence score based on success/failure counts."""
        total = self.helpful_count + self.harmful_count
        if total == 0:
            self.confidence_score = 0.5
        else:
            # Confidence = (successes / total) with Laplace smoothing
            self.confidence_score = (self.helpful_count + 1) / (total + 2)


class PlaybookState(TypedDict):
    """
    Complete state of an agent's playbook.

    This is stored in LangGraph Store and evolves through delta updates.

    Attributes:
        playbook_id: Unique identifier for this playbook
        agent_type: Which agent this playbook belongs to
        entries: List of all playbook entries
        version: Version number (increments with each update)
        total_executions: Number of times agent has executed
        last_pruned_at: When playbook was last pruned
        created_at: Initial creation time
        updated_at: Last modification time
        metadata: Additional configuration (max_entries, thresholds, etc.)
    """
    playbook_id: str
    agent_type: str  # supervisor, researcher, data_scientist, etc.
    entries: List[PlaybookEntry]
    version: int
    total_executions: int
    last_pruned_at: Optional[datetime]
    created_at: datetime
    updated_at: datetime
    metadata: Dict[str, Any]  # max_entries, prune_threshold, etc.


# ============================================================================
# Reflection Insights
# ============================================================================

class ReflectionInsight(BaseModel):
    """
    Insight generated by the Reflector from execution analysis.

    These are converted into PlaybookEntry objects by the Curator.

    Attributes:
        id: Unique identifier for this insight
        content: The insight text
        category: helpful/harmful/neutral
        confidence_score: How confident the reflector is (0-1)
        execution_id: Which execution this came from
        agent_type: Agent that generated this insight
        tags: Categorization tags
        evidence: Supporting evidence for this insight
        recommendation: Actionable recommendation
        created_at: When this insight was generated
    """
    id: str = Field(default_factory=lambda: str(__import__('uuid').uuid4()), description="Unique ID")
    content: str = Field(..., min_length=10, description="Insight text")
    category: Literal["helpful", "harmful", "neutral"] = Field(
        ..., description="Impact category"
    )
    confidence_score: float = Field(
        default=0.75, ge=0.0, le=1.0, description="Reflector confidence"
    )
    execution_id: str = Field(default="", description="Source execution ID")
    agent_type: str = Field(default="", description="Agent type")
    tags: List[str] = Field(default_factory=list, description="Categorization")
    evidence: str = Field(default="", description="Supporting evidence")
    recommendation: str = Field(default="", description="Actionable recommendation")
    created_at: datetime = Field(default_factory=datetime.now, description="Creation time")


class ReflectionInsightList(BaseModel):
    """
    List wrapper for ReflectionInsight objects.

    Used by Osmosis for structured extraction of multiple insights.
    """
    insights: List[ReflectionInsight] = Field(
        default_factory=list,
        description="List of reflection insights"
    )


# ============================================================================
# Playbook Deltas
# ============================================================================

class PlaybookUpdate(BaseModel):
    """
    Update operation for a specific playbook entry.

    Attributes:
        entry_id: ID of entry to update
        updates: Dictionary of fieldâ†’value updates
    """
    entry_id: str = Field(..., description="Entry ID to update")
    updates: Dict[str, Any] = Field(
        default_factory=dict,
        description="Field updates (e.g., {'helpful_count': '+1'})"
    )


class PlaybookDelta(BaseModel):
    """
    Changes to apply to a playbook (incremental update).

    Instead of rewriting the entire playbook (which causes context collapse),
    ACE applies delta updates that add, modify, or remove specific entries.

    Attributes:
        add: New insights to add to playbook
        update: Existing entries to modify
        remove: Entry IDs to remove (pruning)
        execution_id: Which execution triggered this delta
        created_at: When this delta was generated
    """
    add: List[PlaybookEntry] = Field(
        default_factory=list, description="New entries to add"
    )
    update: List[PlaybookUpdate] = Field(
        default_factory=list, description="Entry updates"
    )
    remove: List[str] = Field(
        default_factory=list, description="Entry IDs to remove"
    )
    execution_id: str = Field(default="", description="Source execution")
    created_at: datetime = Field(default_factory=datetime.now)

    def is_empty(self) -> bool:
        """Check if this delta has any changes."""
        return (
            len(self.add) == 0
            and len(self.update) == 0
            and len(self.remove) == 0
        )


# ============================================================================
# Helper Functions
# ============================================================================

def create_initial_playbook(
    agent_type: str,
    max_entries: int = 100,
    prune_threshold: float = 0.95,
) -> PlaybookState:
    """
    Create an empty playbook for a new agent.

    Args:
        agent_type: Agent type (e.g., "researcher", "supervisor")
        max_entries: Maximum playbook size
        prune_threshold: When to trigger pruning (cosine similarity)

    Returns:
        Initial empty PlaybookState
    """
    now = datetime.now()
    playbook_id = f"{agent_type}_v1"

    return PlaybookState(
        playbook_id=playbook_id,
        agent_type=agent_type,
        entries=[],
        version=0,
        total_executions=0,
        last_pruned_at=None,
        created_at=now,
        updated_at=now,
        metadata={
            "max_entries": max_entries,
            "prune_threshold": prune_threshold,
        }
    )


def format_playbook_for_prompt(
    entries: List[PlaybookEntry],
    max_entries: int = 10,
    agent_type: str = "agent"
) -> str:
    """
    Format playbook entries into compact prompt section.

    Args:
        entries: Playbook entries to format
        max_entries: Maximum entries to include
        agent_type: Agent type for header

    Returns:
        Formatted string for injection into system prompt
    """
    if not entries:
        return f"## LEARNED STRATEGIES FOR {agent_type.upper()}\n\n(No strategies learned yet)"

    # Separate by category
    helpful = [e for e in entries if e.category == "helpful"]
    harmful = [e for e in entries if e.category == "harmful"]

    # Sort by effectiveness (confidence * count)
    helpful.sort(
        key=lambda e: e.confidence_score * e.helpful_count,
        reverse=True
    )
    harmful.sort(
        key=lambda e: e.harmful_count,
        reverse=True
    )

    sections = [
        f"## LEARNED STRATEGIES FOR {agent_type.upper()}",
        "",
        "**Apply These Patterns:**"
    ]

    # Top helpful strategies
    for i, entry in enumerate(helpful[:max_entries], 1):
        success_rate = entry.helpful_count / max(
            entry.helpful_count + entry.harmful_count, 1
        )
        sections.append(
            f"{i}. {entry.content} [success: {success_rate:.0%}, confidence: {entry.confidence_score:.0%}]"
        )

    if not helpful:
        sections.append("(No successful patterns learned yet)")

    # Top harmful patterns
    if harmful:
        sections.append("")
        sections.append("**Avoid These Patterns:**")
        for i, entry in enumerate(harmful[:5], 1):
            sections.append(f"{i}. {entry.content}")

    return "\n".join(sections)
