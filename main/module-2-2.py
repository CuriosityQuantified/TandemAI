"""
MODULE 2.2: DeepAgents with Sub-Agents (v0.2)
==============================================

Demonstrates:
1. Supervisor agent with specialized sub-agents (research, analysis, writing)
2. Visible TODO list tracking
3. Full action logging for supervisor and sub-agents
4. CompositeBackend for hybrid storage
5. Multi-step task delegation and synthesis

Based on: langchain-langgraph-hands-on-guide.md Module 2.2
"""

import os
from typing import Dict, Any, Optional
from dotenv import load_dotenv

# DeepAgents imports
from deepagents import create_deep_agent
from deepagents.backends import (
    CompositeBackend,
    StateBackend,
    StoreBackend,
    FilesystemBackend
)

# LangChain imports
from langchain_openai import ChatOpenAI
from langchain_core.tools import tool
from langgraph.checkpoint.memory import MemorySaver
from langchain.agents.middleware import AgentMiddleware

load_dotenv()

# ============================================================================
# CONFIGURATION
# ============================================================================

# Initialize model via OpenRouter (from Module 1.1)
MODEL_CONFIG = {
    "model": "anthropic/claude-sonnet-4.5",
    "openai_api_base": "https://openrouter.ai/api/v1",
    "openai_api_key": os.getenv("OPENROUTER_API_KEY"),
    "temperature": 0.7,
}

print("\n" + "=" * 80)
print("MODULE 2.2: Multi-Agent Research System with DeepAgents v0.2")
print("=" * 80)

# ============================================================================
# CUSTOM TOOLS FOR SUB-AGENTS
# ============================================================================

@tool
def web_search(query: str) -> str:
    """Search the web for information (simulated).

    Use this when you need current information or research data.
    """
    # Simulated search results
    results = {
        "langchain": "LangChain is a framework for developing applications powered by language models. v1.0 released October 2025.",
        "langgraph": "LangGraph is a library for building stateful, multi-actor applications with LLMs. Latest version: v1.0.1.",
        "deepagents": "DeepAgents v0.2 released October 28, 2025. Adds pluggable backends, auto eviction, and conversation summarization.",
    }

    # Find relevant result
    for key, value in results.items():
        if key.lower() in query.lower():
            return f"Search results for '{query}':\n{value}"

    return f"Search results for '{query}':\nGeneral information about AI frameworks and tools."


@tool
def analyze_data(data: str, analysis_type: str = "summary") -> str:
    """Analyze data and provide insights.

    Args:
        data: The data to analyze
        analysis_type: Type of analysis (summary, comparison, trend)
    """
    word_count = len(data.split())
    char_count = len(data)

    analysis = f"""
Analysis Type: {analysis_type}
Data Length: {word_count} words, {char_count} characters

Key Insights:
- Data contains information about AI frameworks
- Suitable for technical documentation
- Analysis complete
"""
    return analysis


@tool
def format_document(content: str, format_type: str = "markdown") -> str:
    """Format content into structured document.

    Args:
        content: Raw content to format
        format_type: Output format (markdown, html, plain)
    """
    if format_type == "markdown":
        formatted = f"""# Research Report

## Summary
{content}

## Conclusion
Research completed successfully.

---
*Generated by DeepAgents Multi-Agent System*
"""
        return formatted

    return content


# ============================================================================
# LOGGING MIDDLEWARE FOR VISIBILITY
# ============================================================================

class VerboseLoggingMiddleware(AgentMiddleware):
    """Middleware to log all agent actions for visibility."""

    def __init__(self, agent_name: str):
        super().__init__()
        self.agent_name = agent_name

    def before_model(self, state, runtime):
        """Log before model calls."""
        print(f"\n{'‚îÄ' * 80}")
        print(f"ü§ñ [{self.agent_name}] Thinking...")
        print(f"   Messages in context: {len(state.get('messages', []))}")
        return state

    def after_model(self, state, runtime):
        """Log after model calls."""
        last_message = state.get("messages", [])[-1] if state.get("messages") else None
        if last_message:
            content = getattr(last_message, 'content', '')
            if content:
                preview = content[:100] + "..." if len(content) > 100 else content
                print(f"üí≠ [{self.agent_name}] Response: {preview}")
        return state

    def wrap_tool_call(self, tool_name, tool_args, next_fn):
        """Log tool calls."""
        print(f"\nüîß [{self.agent_name}] Using tool: {tool_name}")
        print(f"   Args: {tool_args}")

        result = next_fn()

        result_preview = str(result)[:150] + "..." if len(str(result)) > 150 else str(result)
        print(f"‚úÖ [{self.agent_name}] Tool result: {result_preview}")

        return result


# ============================================================================
# SUB-AGENT DEFINITIONS
# ============================================================================

print("\nüìã Initializing Sub-Agents...")

# Research Sub-Agent
research_subagent = {
    "name": "researcher",
    "description": "Specialized research agent that searches for information on AI frameworks, tools, and technologies",
    "tools": [web_search],
    "system_prompt": """You are a research specialist focused on AI frameworks and technologies.

Your responsibilities:
- Search for accurate, up-to-date information
- Gather data from multiple sources when needed
- Provide comprehensive research findings
- Focus on facts and verifiable information

When given a research task:
1. Break down the query into specific search terms
2. Use web_search tool for each topic
3. Compile findings clearly
4. Highlight key facts and dates
""",
    "middleware": [VerboseLoggingMiddleware("Researcher")]
}

# Analysis Sub-Agent
analysis_subagent = {
    "name": "analyst",
    "description": "Specialized analysis agent that processes research data and extracts insights",
    "tools": [analyze_data],
    "system_prompt": """You are a data analyst specializing in AI technology trends.

Your responsibilities:
- Analyze research data for patterns and insights
- Compare different technologies objectively
- Identify trends and implications
- Provide actionable recommendations

When given an analysis task:
1. Review the data thoroughly
2. Use analyze_data tool to process information
3. Extract key insights and comparisons
4. Present findings with supporting evidence
""",
    "middleware": [VerboseLoggingMiddleware("Analyst")]
}

# Writing Sub-Agent
writing_subagent = {
    "name": "writer",
    "description": "Specialized writing agent that creates well-structured technical documents",
    "tools": [format_document],
    "system_prompt": """You are a technical writer specializing in AI documentation.

Your responsibilities:
- Create clear, structured documents
- Format content for readability
- Maintain consistent style and tone
- Ensure technical accuracy

When given a writing task:
1. Organize information logically
2. Use format_document tool to structure content
3. Create headings and sections appropriately
4. Ensure professional presentation
""",
    "middleware": [VerboseLoggingMiddleware("Writer")]
}

print("‚úÖ Research Sub-Agent: Configured with web_search tool")
print("‚úÖ Analysis Sub-Agent: Configured with analyze_data tool")
print("‚úÖ Writing Sub-Agent: Configured with format_document tool")

# ============================================================================
# HYBRID STORAGE BACKEND (v0.2 Feature)
# ============================================================================

print("\nüíæ Configuring Hybrid Storage Backend (v0.2)...")

# Create workspace directory for filesystem backend
workspace_dir = "/Users/nicholaspate/Documents/01_Active/Corp_Strat/open-source-CC/docs/learning-plan/lessons/agent_workspace"
os.makedirs(workspace_dir, exist_ok=True)

# Composite backend with hybrid storage
def create_composite_backend(rt):
    """Create hybrid storage backend routing different paths to different backends."""
    return CompositeBackend(
        default=StateBackend(rt),  # Ephemeral scratch space
        routes={
            # Note: StoreBackend requires LangGraph Store setup
            # For this demo, we'll use StateBackend for memories too
            "/memories/": StateBackend(rt),
            "/workspace/": FilesystemBackend(root_dir=workspace_dir),
        }
    )

print(f"‚úÖ Hybrid Backend Configured:")
print(f"   - /workspace/ ‚Üí Real filesystem ({workspace_dir})")
print(f"   - /memories/ ‚Üí Ephemeral state storage")
print(f"   - Default ‚Üí Ephemeral state storage")

# ============================================================================
# SUPERVISOR AGENT
# ============================================================================

print("\nüëî Creating Supervisor Agent...")

supervisor_agent = create_deep_agent(
    model=ChatOpenAI(**MODEL_CONFIG),
    tools=[],  # Supervisor has no direct tools - delegates to sub-agents
    subagents=[research_subagent, analysis_subagent, writing_subagent],
    backend=create_composite_backend,
    checkpointer=MemorySaver(),  # Enable conversation memory
    middleware=[VerboseLoggingMiddleware("Supervisor")],
    system_prompt="""You are a research project supervisor managing a team of specialized agents.

Your team:
- researcher: Searches for information on AI topics
- analyst: Analyzes research data and extracts insights
- writer: Creates structured technical documents

Your process for complex tasks:
1. ALWAYS start by using write_todos to create a task plan
2. Break down the user's request into subtasks
3. Delegate each subtask to the appropriate specialist using the 'task' tool
4. Synthesize results from all specialists
5. Update todos as tasks complete

Example delegation:
- Research tasks ‚Üí task(subagent="researcher", query="Search for LangChain v1.0 features")
- Analysis tasks ‚Üí task(subagent="analyst", query="Analyze research data on frameworks")
- Writing tasks ‚Üí task(subagent="writer", query="Create formatted report from findings")

IMPORTANT:
- Use write_todos at the start to show your plan
- Delegate ALL specialized work to sub-agents
- You coordinate and synthesize, not execute
- Update todos as you progress
"""
)

print("‚úÖ Supervisor Agent Created")
print("   - Manages 3 specialized sub-agents")
print("   - Uses TodoListMiddleware for planning")
print("   - Uses SubAgentMiddleware for delegation")

# ============================================================================
# HELPER FUNCTIONS
# ============================================================================

def display_todos(state: Dict[str, Any]) -> None:
    """Display current TODO list if present."""
    todos = state.get("todos", [])
    if todos:
        print("\n" + "=" * 80)
        print("üìù TODO LIST")
        print("=" * 80)
        for i, todo in enumerate(todos, 1):
            status_icon = {"pending": "‚è≥", "in_progress": "üîÑ", "completed": "‚úÖ"}.get(
                todo.get("status", "pending"), "‚ùì"
            )
            print(f"{i}. {status_icon} [{todo.get('status', 'pending').upper()}] {todo.get('content', todo)}")
        print("=" * 80)


def run_agent_with_visibility(query: str) -> Dict[str, Any]:
    """Run agent with full visibility into actions and todos."""

    print("\n" + "üéØ" * 40)
    print(f"USER QUERY: {query}")
    print("üéØ" * 40)

    # Create config for thread-based memory
    config = {"configurable": {"thread_id": "research-session-1"}}

    # Invoke supervisor agent
    print("\nüöÄ Starting Multi-Agent Research System...")
    print("‚îÄ" * 80)

    result = supervisor_agent.invoke(
        {"messages": [{"role": "user", "content": query}]},
        config=config
    )

    # Display todos if created
    display_todos(result)

    # Display final response
    print("\n" + "=" * 80)
    print("üìä FINAL RESPONSE")
    print("=" * 80)
    final_message = result["messages"][-1]
    print(final_message.content)
    print("=" * 80)

    return result


# ============================================================================
# EXAMPLE 1: Simple Research Task
# ============================================================================

print("\n\n" + "üî¨" * 40)
print("EXAMPLE 1: Simple Research Query")
print("üî¨" * 40)

result1 = run_agent_with_visibility(
    "Research LangChain v1.0 and provide a brief summary"
)

# ============================================================================
# EXAMPLE 2: Complex Multi-Step Task
# ============================================================================

print("\n\n" + "üî¨" * 40)
print("EXAMPLE 2: Complex Multi-Agent Task")
print("üî¨" * 40)

result2 = run_agent_with_visibility(
    """Research the following AI frameworks and create a comparison report:
    1. LangChain v1.0
    2. LangGraph v1.0.1
    3. DeepAgents v0.2

    Analyze the key features of each and write a formatted technical document."""
)

# ============================================================================
# EXAMPLE 3: File System Integration
# ============================================================================

print("\n\n" + "üî¨" * 40)
print("EXAMPLE 3: With File System Storage")
print("üî¨" * 40)

result3 = run_agent_with_visibility(
    """Research DeepAgents v0.2 backend system and save findings to
    /workspace/deepagents_backends.md"""
)

# Check if file was created
output_file = os.path.join(workspace_dir, "deepagents_backends.md")
if os.path.exists(output_file):
    print(f"\n‚úÖ File created: {output_file}")
    with open(output_file, 'r') as f:
        content = f.read()
        print(f"üìÑ File contents ({len(content)} chars):")
        print(content[:500] + "..." if len(content) > 500 else content)
else:
    print(f"\n‚ö†Ô∏è  File not found: {output_file}")

# ============================================================================
# SUMMARY
# ============================================================================

print("\n\n" + "=" * 80)
print("MODULE 2.2 SUMMARY")
print("=" * 80)

summary = """
‚úÖ Demonstrated Concepts:

1. Multi-Agent Architecture:
   - Supervisor agent for coordination
   - 3 specialized sub-agents (research, analysis, writing)
   - Clear delegation via 'task' tool

2. Visibility & Observability:
   - TODO list tracking via write_todos tool
   - VerboseLoggingMiddleware for action logging
   - All agent thoughts and tool calls visible

3. DeepAgents v0.2 Features:
   - CompositeBackend for hybrid storage
   - Filesystem integration (/workspace/)
   - Ephemeral state for scratch work

4. Production Patterns:
   - Specialized agents with focused responsibilities
   - Systematic task breakdown and delegation
   - Checkpointing for conversation memory

üìö Key Learnings:

- Supervisor agents coordinate, sub-agents execute
- TODO lists help track multi-step workflows
- Middleware enables custom logging and monitoring
- v0.2 backends provide flexible storage strategies
- Sub-agent specialization improves output quality

üéØ Next Steps:

1. Try different queries to see delegation patterns
2. Add custom tools to sub-agents
3. Experiment with StoreBackend for persistence
4. Implement error handling and retries
5. Add human-in-the-loop approval workflows
"""

print(summary)
print("=" * 80)

print("\n‚ú® Module 2.2 Complete! ‚ú®\n")
